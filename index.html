<!doctype html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<!-- Edit me start! -->
		<title>An Integrated and Trusted Scientific and Statistical Computing Core</title>
		<meta name="description" content="Slides describing my experience and ideas for NIH SSCC ">
		<meta name="author" content=" Yaroslav O. Halchenko ">
		<!-- Edit me end! -->

		<link rel="stylesheet" href="reveal.js/dist/reset.css">
		<link rel="stylesheet" href="reveal.js/dist/reveal.css">
		<link rel="stylesheet" href="reveal.js/dist/theme/beige.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">


<!-- Start of slides -->
<section>
  <section>
	  <a href="http://centerforopenneuroscience.org/"><img data-src="pics/con-ccn-dartmouth-letterhead.svg"></a>
  <h2>An Integrated and Trusted Scientific and Statistical Computing Core</h2>
    <div style="margin-top:1em;text-align:center">
    <table style="border: none;">
    <tr>
	<td>
          Yaroslav O. Halchenko<br><small><a href="https://twitter.com/yarikoptic" target="_blank">
		  <img data-src="pics/twitter.png" style="height:30px;margin:0px" />@yarikoptic</a></small>
      </td>
    </tr>
    <tr>
      <td>
		<small><a href="http://centerforopenneuroscience.org/" target="_blank">Center for Open Neuroscience</a>
          <br><a href="https://pbs.dartmouth.edu/" target="_blank">Department of Psychological and Brain Sciences</a>
          <br><a href="https://www.dartmouth.edu/ccn/" target="_blank">Center for Cognitive Neuroscience</a><br>
		  <a href="http://www.dartmouth.edu" target="_blank">Dartmouth College</a></small>
		<!--<img style="height:150px;" data-src="pics/con-logo_blue_big.svg">-->
      </td>
    </tr>
    </table>
    </div>
<!--
  <p style="z-index: 100;position: fixed;background-color:#ede6d5;font-size:35px;box-shadow: 10px 10px 8px #888888;margin-top:0px;margin-bottom:100px;margin-left:1000px">
        <img src="pics/QRcode_hhu.png" height="200">
    </p>
<br><br><small>
    Slides: <a href="https://doi.org/10.5281/zenodo.6346849" target="_blank">
    DOI 10.5281/zenodo.6346849</a> (Scan the QR code)
    <br>
</small>
-->
<small>
  <!-- TODO place them there; Add QR code how in template -->
<br>Live slides/Sources (Git repo - add /.git): <a href="https://datasets.datalad.org/centerforopenneuroscience/talks/2022-nih-compcore/">http://datasets.datalad.org/repronim/artwork/talks/webinar-2020-reprocomp/</a>
<br>
    <small>
	 <a href="http://datalad.org" target="_blank"> <img  style="height:150px;margin:20px" data-src="pics/datalad_D.svg"/></a>
	 <a href="http://neuro.debian.net" target="_blank"> <img  style="height:150px;margin:20px" data-src="pics/neurodebian.png"/></a>
	 <a href="http://repronim.org" target="_blank"> <img  style="height:150px;margin:20px"  data-src="pics/repronim-logo-vertical.svg"/></a>
	 <a href="https://dandiarchive.org" target="_blank"> <img  style="height:150px;margin:20px"  data-src="pics/dandi-logo-square.svg"/></a>

<!--	 <a href="https://bids.neuroimaging.io" target="_blank"> <img  style="height:150px;margin:20px" data-src="pics/BIDS_Logo.png"/></a> -->
	 <a href="https://github.com/myyoda/poster/blob/master/ohbm2018.pdf" target="_blank"> <img  style="height:150px;margin:20px" data-src="pics/yoda.svg"/></a>
 </small>

</small>
  </section>
</section>

<section data-transition-speed="zoom">

  <section>
  <div class="r-stack">
  <img style="height:800px" data-src="pics/yarik-goal.svg"/>
  </div>
  </section>

  <section>
	<h1>Who am I?</h1>
	<img style="height:400px" data-src="pics/borrowed/twitter-unsolicited-advice.png"/>
  </section>

  <section>
	<h3>Brief Bio</h3>
	<p>Born in Siberia (RSFSR, USSR), Grew up in Ukraine, Matured in U.S.A.</p>
	<ul>
	  <li class="fragment"><b>-1994 Physics Mathematics Gymnasium #17 (Ukraine):</b><br>
		<small> Regional&State Physics and Programming
		  competitions. MS-DOS. Borland Pascal</small></li>

	  <li class="fragment"><b>-1999 VSTU (Ukraine): Masters in Opto-Electronic Engineering</b><br>
		<small> (@yarikoptic). State Physics and International ACM Programming
		  competitions. Spine diagnostic apparatus. Member of "Small Academy of Science of
		  Ukraine". SPIE. Soros Fellowship (twice). MS-DOS/Windows.
		  Borland Pascal, Delphi
	  </small></li>

	  <li class="fragment"><b>-2003 University of New Mexico: Masters in Computer Science</b><br>
		<small><a href="http://www.bcl.hamilton.ie/~barak/">B.Pearlmutter</a>.
		  SOBI/JADE ICA for single trial MEG. Favorite course: Data structures
		  and algorithms.
		  <a href="https://debian.org">Debian GNU/Linux</a>.
		  C, Matlab, shell. CVS
	  </small></li>

	  <li class="fragment"><b>-2009 Rutgers-Newark/NJIT:
		  Ph.D. in Computer Science</b><br>
		<small><a href="http://rubic-web.rutgers.edu/people.html">S.Hanson</a>.
		  <a href="http://dx.doi.org/10.1162/neco.2007.09-06-340">fMRI decoding (RFE SVM)</a>.
		  <a href="https://link.springer.com/article/10.1385/NI:2:1:071?noAccess=true">RUMBA</a>.
		  HPC sysadmin (cfengine, PBS).
		  <a href="https://www.fz-juelich.de/SharedDocs/Personen/INM/INM-7/EN/Hanke_m.html">M.Hanke</a>.
		  Debian pkg-exppsy (for FSL and PyEPL).
		  <a href="https://nm.debian.org/person/yoh/">Official Debian developer</a>.
		  <a href="https://arxiv.org/abs/1307.2150">fMRI/EEG (TRANS)fusion</a>.
		  <a href="http://pymvpa.org">PyMVPA</a>.
		  C++, Python. SVN, GIT. 1 wife, 3 kids
	  </small></li>
	  <li class="fragment"><b>- NOW Dartmouth College, PBS Department: <br>
		  Postdoc, Scientist, Research Assistant/Associate Professor</b><br>
		<small><a href="https://haxbylab.dartmouth.edu/">J.Haxby</a>.
		  <a href="http://pymvpa.org">PyMVPA</a>
		  (<a href="http://dx.doi.org/10.1016/j.neuron.2011.08.026">Hyperalignment</a>,
		  ...),
		  <a href="https://neuro.debian.net">NeuroDebian</a>,
		  <a href="https://datalad.org">DataLad</a>,
		  <a href="https://repronim.org">ReproNim</a>,
		  <a href="https://dandiarchive.org">DANDI</a>,
		  ...
		  <a href="https://github.com/yarikoptic/coop">Chicken Coop</a>,
		  ...
		  <a href="https://centerforopenneuroscience.org/">CON</a>:
		</small>
	  </li>
	</ul>
  </section>

  <section>
	<div class="r-stack">
	  <img style="width:2000px" data-src="pics/con-webshot-20150812-front-up.png"/>
	  <!-- TODO update this compilation! prepend with proper Ack-->
	  <img class="fragment" style="width:1000px" data-src="pics/con-ack-bmbf.png"/>
	  <img class="fragment" data-src="pics/borrowed/con-webshot-20150812-front-down.png"/>
	  <img class="fragment" style="width:2000px" data-src="pics/con-principles.png"/>
	  <!-- <img class="fragment" style="width:500px"
				data-src="pics/con-ack-joeybenetc-extended.svg"/> -->
	</div>
  </section>

</section>

<section>
	<section data-markdown>
	  <textarea data-template>
## Integration & Trust Tiers

  - Psychological/Social
  - Data
  - Methods/Analytics
  - Data modalities
  - Software Systems
  - Services
	  </textarea>
	</section>
</section>

<section>
  <section>
	<h1>Trust is largely a social aspect</h1>
	<h2>How do we convince ourselves (and others) that our results are correct?</h2>
  </section>

  <section>
	<h2>How do we convince ourselves?</h2>
	<h3>It is hard since most of the data is DERIVED data</h3>
	<p  style="font-size:120%">Share accountability among</p>
	<ul style="font-size:120%">
	  <li>3rd-party <br> (manufacturers, methods & software developers)</li>
	  <li>data collection/QA team</li>
	  <li>analysis team</li>
	</ul>
  </section>

  <section>
	<h2>3rd party?</h2>
	  <img style="width:2000px"
		   data-src="pics/god-is-at-the-computer.jpg"/>
	  <br>
	  <small>Unknown artist/origin, borrowed from <br><a href="http://blogs.quovantis.com/god-programmer/">http://blogs.quovantis.com/god-programmer/</a></small>
  </section>

  <section>
	<h2>Nuisance study</h2>
	<img data-src="pics/f1000-webshot-20200930.png"/>

	<small>
	  Cheng CP and Halchenko YO. A new virtue of phantom MRI data: explaining variance in human participant data [version 1]. F1000Research 2020, 9:1131 (<a href=https://doi.org/10.12688/f1000research.24544.1>https://doi.org/10.12688/f1000research.24544.1</a>
	  <br><a href="http://datasets.datalad.org/centerforopenneuroscience/nuisance/presentations/2020-NNL/">http://datasets.datalad.org/centerforopenneuroscience/nuisance/presentations/2020-NNL/</a>
	contains a more detailed presentation</small>
  </section>

  <section data-markdown  data-separator="^\n----\n" data-vertical="^\n---\n"><textarea data-template>
## Results a nutshell

- *Somewhat surprising*:
  - Variance in SNR through time in phantom QA data can **very well** (R2=0.53) be
  explained by intrinsic factors (time of acquisition, SAR, position
  in the scanner).
- *Our hypothesis confirmed*:
  - **A proxy measure of *MRI scanner health*, such as SNR from phantom
  data, can explain some variance in human data results**

----
## Take home

- *Conclusions*:
  - More variance can be explained than what we thought
- *Work could be done together with data acquisition sites to*:
  - **increase sensitivity of MRI scanner health *deterioration***
  - **include phantom QA data in your normative databases**
  - **provide phantom QA metrics so they could be conveniently included
in the human studies QA/analyses**
  - **improve automated screening/QA of human participants data**
  </textarea></section>

  <section>
	<h2>How can we minimize variance from teams?</h2>

	<ul>
	  <li>provide guidelines</li>
	  <li>minimize human IO: automate data collection/harmonization</li>
	  <li>encourage simulations: software/data testing</li>
	  <li>facilitate peer-review: by team not only reviewers</li>
	  <li>facilitate provenance/accountability tracking</li>
	  <li>facilitate reuse: user testing</li>
	</ul>
  </section>


  <section>
	<h2>Example 5-step guidelines from P41 ReproNim</h2>
	<a href="http://5steps.repronim.org"><img data-src="pics/repronim-5steps.png"/></a>
  </section>

</section>

<section>
	<section>
	  <img style="width:2000px" data-src="pics/pymvpa_logo_fromfusionposter.svg"/>
	</section>

	<section>
	  <h1>PyMVPA Features</h1>
	  <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2664559/">
	  <img style="width:2000px" data-src="pics/pymvpa-features.png"/></a>
	</section>

	<section data-markdown>
	  <textarea data-template>
		## PyMVPA: Integration of Methods/Modalities

		- **1st open source machine learning (ML) toolkit for neuroimaging data**
		- Unified data structure (Dataset) for analysis of
			- channel data (EEG/MEG)
			- volumetric data (nibabel)
			- surface data (based on AFNI)
			- sample/feature attributes (conditions/coordinates)
		- Unified (reversible) Mapper/Learner concepts:
			- Dimensionality reduction: masking, SVD, etc.
			- Searchlight-ing & <a href="http://www.franciscopereira.org/searchmight/">Searchmight-ing</a>
			- <a href="http://dx.doi.org/10.1016/j.neuron.2011.08.026">Hyperalignments</a>
		- Unified interfaces to external libraries
			- libsvm
			- shogun
			- MDP
			- scikit-learn
			- R libraries (via RPy2)
	  </textarea>
	</section>

	<section>
	  <div class="r-stack">
		<img style="width:1000px" data-src="pics/pymvpa-classification.png"/>
		<img class="fragment" style="width:1000px" data-src="pics/pymvpa-searchlight-step.png"/>
		<img class="fragment" style="width:1000px" data-src="pics/pymvpa-searchlight.png"/>
	  </div>
	</section>

	<section>
	  <h2>Applicable across different modalities</h2>
	  <a href="http://dx.doi.org/10.3389/neuro.11.003.2009">
	  <img style="width:1000px" data-src="pics/pymvpa-many-modalities.png"/></a>
	</section>

	<section>
	  <h2>And even for integrating across modalities</h2>
		  <h3>TRANSFusion: EEG fMRI mapping</h3>
		  <a href="https://arxiv.org/abs/1307.2150"><img style="width:1000px" data-src="pics/pymvpa-transfusion.png"/></a>
	</section>

	<section>
	  <h2>And others could take advantage of it:</h2>
		  <a href=""><img style="width:1000px" data-src="pics/pymvpa-studies-20160407.png"/></a>
	</section>

	<section>
	  <h3>Overall:</h3>

	  <ul>
		<li>Unification of data structures and interfaces in
		PyMVPA allowed for integration across methodologies, software
		  implementations, and data modalities.</li>
		<li>Explicit separation of training/testing data in
		CrossValidation helped users to avoid double-dipping
		regardless of the complexity of the model.</li>
		<li>Extensive unit-, example- and documentation testing
		improved our and user trust in obtained results.</li>
	</section>

	<section>
	  <h3>But it brought a challenge:</h3>

	  <p>"... The PyMVPA manual has a picture of a <b>dude performing pattern-classification on fMRI data with
his freaking cellphone. Awesome</b>.  If you can do it on a cellphone,
		then I'm set". </p>

	  <img data-src="pics/pymvpa_on_phone.jpg"/>

	  <div class="fragment">
	  <p>I have a computer (MAC). <br> Hours later, I'm wrestling with MAC OS (Leopard) ...</p>
	  </div>
	  <div class="fragment">
	  <p><b>PyMVPA follow up</b>: 12.5 hours to happy time</p>
	  <p>
	  <small>
		<a href="http://kvaden.blogspot.com/2009/03/installing-pymvpa-on-leopard-mac-os.html">http://kvaden.blogspot.com/2009/03/installing-pymvpa-on-leopard-mac-os.html</a></small></p>

	  </div>
	</section>

</section>

<section>
  <section>
	<a href="https://neuro.debian.net">
	  <img style="width:2000px" data-src="pics/neurodebian_logo_web_banner.png"/></a>
	</section>

  <section>
	<h2>Solution to system integration challenge:</h2>
	<a href="https://neuro.debian.net">
	  <img style="width:2000px" data-src="pics/neurodebian-overview.png"/></a>
  </section>

  <section>
	<h2>More detail on why and how:</h2>
	<a href="">
	  <img style="width:2000px" data-src="pics/borrowed/HH12-webshot-20130331.png"/></a>
	<small>
	  <br>
	  <a href="https://www.frontiersin.org/articles/10.3389/fninf.2012.00022/full">
		Halchenko, Y. O. and Hanke, M. (2012). Open is not enough. Let‚Äôs take the
	  next step: An integrated, community-driven computing platform for
	  neuroscience. Frontiers in Neuroinformatics, 6(00022). PMC3458431</a>
	  </small>
  </section>

  <section>
	<h2>NeuroDebian from user perspective:</h2>
	<img style="width:2000px" data-src="pics/neurodebian-user.png"/>
  </section>

  <section>
	<h2>Under-the-hood for PyMVPA user:</h2>
	<img style="width:2000px" data-src="pics/neuropy_history.svg"/>
  </section>

  <section>
	<h2>Under-the-hood for a NeuroDebian developer:</h2>
	<img data-src="pics/nd_overview.svg"/>
  </section>

  <section>
	  <h2>Overall:</h2>

	  <h3>Integration of software projects within a distribution</h3>
	  <ul style="font-size:120%">
		<li>greatly reduced user&developer burden in software
		  installations/maintenance</li>
		<li>improved trust in correct operation</li>
		<li>helped to ensure adherence to legal
		  norms</li>
		<li>facilitated collaboration, experimentation, and
		  reproducibility.
	  </li></ul>
	</section>

	<section>
	  <h2>But it revealed a shortcoming:</h2>
	  <h3>Software platforms are not designed for managing data!</h3>
		  <ul style="font-size:120%">
			<li>modularity is less well defined <br>
			  (interest could be in specific group of files, videos-vs-images or humans-vs-objects, etc)</li>
			<li>data is less volatile (lesser versions, only a few files change)</li>
			<li>tarballs are inefficient</li>
			<li>we cannot host copies of all data</li>
			<li>cacophony of authentication schemes, interfaces, protocols</li>
			<li>difficulty to share new or derived data</li>
		  </ul>
	</section>
</section>

<section>
  <section>
	<a href="https://datalad.org">
	  <img style="height:400px"
		   data-src="pics/datalad_logo_wide.gif"/></a>
	<p style="margin-top:200px;font-size:150%">
	  A data management suite that makes data access and management as
	  easy as managing code and software!
	  </p>
  </section>

  <section data-transition="slide">
	<h2>DataLad in one figure</h2>
	<img style="width:2000px" data-src="pics/datalad_process_tuned_00.png">
  </section>

  <section>
  <h2>An example in "files":</h2>
  <img style="" height="800px" data-src="pics/virtual_dirtree.png">

  <p>For management of computing containers with DataLad, see <a href="https://github.com/datalad/datalad-container/">datalad-container</a> extension, and <a href="https://github.com/ReproNim/containers/">ReproNim/containers</a> DataLad dataset.</p>
</section>

<section>
  <h2>Meet one of the "largest" Git "repositories"</h2>
  <img style=""  data-src="pics/datasets.datalad.org-20220313.png">

  <p>over 6,000 Git repositories as "subdatasets", <br>
	with access to almost 500TB of neural data</p>
</section>

</section>

<section>

  <aside class="notes">
    Shhh, these are your private notes üìù
  </aside>

  
<section data-markdown>
  <textarea data-template>
    ## Slide 1
    A paragraph with some text and a [link](http://hakim.se).
    ---
    ## Slide 2
    ---
    ## Slide 3
  </textarea>
</section>
</section>
<section data-markdown>
  ```python
  print(1)
  ```
</section>

<!-- End of slides -->


			</div>
		</div>

		<script src="reveal.js/dist/reveal.js"></script>
		<script src="reveal.js/plugin/notes/notes.js"></script>
		<script src="reveal.js/plugin/markdown/markdown.js"></script>
		<script src="reveal.js/plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// The "normal" size of the presentation, aspect ratio will be preserved
				// when the presentation is scaled to fit different resolutions. Can be
				// specified using percentage units.
				width: 1280,
				height: 960,
				// Factor of the display size that should remain empty around the content
				margin: 0.3,
				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 1.0,

				controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: 'c',
				pdfSeparateFragments: false,
				pdfMaxPagesPerSlide: 1,
				pdfPageHeightOffset: -1,
				transition: 'slide', // none/fade/slide/convex/concave/zoom
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
